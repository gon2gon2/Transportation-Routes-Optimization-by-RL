{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "learning_rate = 0.0005\n",
    "gamma         = 0.98\n",
    "lmbda         = 0.95\n",
    "eps_clip      = 0.1\n",
    "K_epoch       = 3\n",
    "T_horizon     = 20\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, state_dim,action_dim,learning_rate):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.tau = 0.001\n",
    "        super(Agent,self).__init__()\n",
    "        self.memory = []\n",
    "\n",
    "        self.fc1 = nn.Linear(self.state_dim,256)\n",
    "        self.policy = nn.Linear(256, self.action_dim)\n",
    "        \n",
    "        self.fc2 = nn.Linear(self.state_dim,256)\n",
    "        self.value = nn.Linear(256, 5)\n",
    "        \n",
    "        self.fc2_target = nn.Linear(self.state_dim,256)\n",
    "        self.value_target = nn.Linear(256,5)\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(),lr = learning_rate)\n",
    "        self.fc2_target.bias = self.fc2.bias\n",
    "        self.fc2_target.weight = self.fc2.weight\n",
    "        \n",
    "        self.value_target.bias = self.value.bias\n",
    "        self.value_target.weight = self.value.weight\n",
    "    def get_action(self,x, softmax_dim = 0):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.policy(x)\n",
    "        prob = F.softmax(x, dim = softmax_dim)\n",
    "        return prob\n",
    "    \n",
    "    def get_value(self,x):\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.value(x)\n",
    "        return x\n",
    "    \n",
    "    def get_target_value(self,x):\n",
    "        x = F.relu(self.fc2_target(x))\n",
    "        x = self.value_target(x)\n",
    "        return x\n",
    "    \n",
    "    def put_data(self,data):\n",
    "        self.memory.append(data)\n",
    "    \n",
    "    \n",
    "        '''    \n",
    "        def soft_update(self):\n",
    "            print((self.fc2_target.bias * (1.0 - self.tau) + self.fc2.bias * self.tau).detach())\n",
    "            self.fc2_target.bias = (self.fc2_target.bias * (1.0 - self.tau) + self.fc2.bias * self.tau).detach()\n",
    "\n",
    "            self.fc2_target.weight = self.fc2.weight.bias * (1.0 - self.tau) + self.fc2.weight * self.tau\n",
    "\n",
    "            self.value_target.bias = self.value.bias * (1.0 - self.tau) + self.value.bias * self.tau\n",
    "            self.value_target.weight = self.value.weight * (1.0 - self.tau) + self.value.weight * self.tau\n",
    "        '''\n",
    "    def make_batch(self):\n",
    "        state_list, action_list, reward_list, next_state_list, prob_list, done_list = [],[],[],[],[],[]\n",
    "        for data in self.memory:\n",
    "            state,action,reward,next_state,prob,done = data\n",
    "            state_list.append(state)\n",
    "            action_list.append([action])\n",
    "            reward_list.append([reward])\n",
    "            prob_list.append([prob])\n",
    "            next_state_list.append(next_state)\n",
    "            done_mask = 0 if done else 1\n",
    "            done_list.append([done_mask])\n",
    "        self.memory = []\n",
    "        \n",
    "        s,a,r,next_s,done_mask,prob = torch.tensor(state_list,dtype=torch.float),\\\n",
    "                                        torch.tensor(action_list),torch.tensor(reward_list),\\\n",
    "                                        torch.tensor(next_state_list,dtype=torch.float),\\\n",
    "                                        torch.tensor(done_list,dtype = torch.float),\\\n",
    "                                        torch.tensor(prob_list)\n",
    "        return s,a,r,next_s,done_mask,prob\n",
    "    \n",
    "    def train(self):\n",
    "        state,action,reward, next_state,done_mask,action_prob = self.make_batch()\n",
    "\n",
    "        for i in range(K_epoch):\n",
    "            global a\n",
    "            global b\n",
    "            next_get_value = self.get_value(next_state)\n",
    "            now_get_value = self.get_value(state)\n",
    "            td_error = reward + gamma * next_get_value.mean(-1) * done_mask\n",
    "            delta = td_error - now_get_value.mean(-1)\n",
    "            delta = delta.detach().numpy()\n",
    "            advantage_list = []\n",
    "            advantage = 0.0\n",
    "            for delta_t in delta[::-1]:\n",
    "                advantage = gamma * lmbda * advantage + delta_t[0]\n",
    "                advantage_list.append([advantage])\n",
    "            advantage_list.reverse()\n",
    "            advantage = torch.tensor(advantage_list,dtype = torch.float)\n",
    "            \n",
    "            \n",
    "            now_action = self.get_action(state,softmax_dim = 1)\n",
    "            now_action = now_action.gather(1,action)\n",
    "            \n",
    "            ratio = torch.exp(torch.log(now_action) - torch.log(action_prob))\n",
    "            \n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio , 1-eps_clip, 1 + eps_clip) * advantage\n",
    "            \n",
    "            \n",
    "            target_net_td_error = reward + gamma * self.get_target_value(next_state) * done_mask\n",
    "            target_net_td_error =target_net_td_error.reshape(-1,5,1).repeat(1,1,5)\n",
    "            normal_net = self.get_value(state)\n",
    "            normal_net = normal_net.reshape(-1,1,5).repeat(1,5,1)\n",
    "            \n",
    "            value_loss = target_net_td_error - normal_net\n",
    "            \n",
    "            \n",
    "            hubber_1 = torch.where(value_loss>=0,torch.tensor([0]),torch.tensor([1])).float() * torch.tensor([0.1-1,0.3-1,0.5-1,0.7-1,0.9-1])\n",
    "            hubber_2 = torch.where(value_loss<0,torch.tensor([0]),torch.tensor([1])).float() * torch.tensor([0.1,0.3,0.5,0.7,0.9]).float()\n",
    "            hubber = hubber_1 + hubber_2\n",
    "            \n",
    "            value_loss = value_loss * hubber\n",
    "            \n",
    "            \n",
    "            value_loss = torch.sum(value_loss,dim = -1)\n",
    "            value_loss = value_loss.mean()#torch.mean()\n",
    "            \n",
    "            loss = - torch.min(surr1,surr2).mean() + value_loss\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from Building import Building\n",
    "#from Agent import Agent\n",
    "import time\n",
    "#====================================================================================\n",
    "\n",
    "\n",
    "#====================================================================================\n",
    "#Building Setting\n",
    "lift_num = 1\n",
    "buliding_height = 5\n",
    "max_people_in_floor = 8\n",
    "max_people_in_elevator = 10\n",
    "\n",
    "add_people_at_step = 25\n",
    "add_people_prob = 0.8\n",
    "\n",
    "#Create building with 4 elevators, height 10, max people 30 in each floor\n",
    "building = Building(lift_num, buliding_height, max_people_in_floor,max_people_in_elevator)\n",
    "\n",
    "#Agent controls each elevator\n",
    "#agent = Agent(buliding_height, lift_num, 4)\n",
    "#agent.reload(280)\n",
    "#The goal is to bring down all the people in the building to the ground floor\n",
    "\n",
    "epochs = 1000\n",
    "max_steps = 100\n",
    "global_step = 0\n",
    "T_horizon = 20\n",
    "reward_list = []\n",
    "print_interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Agent((buliding_height)+ max_people_in_elevator + (lift_num *2),4,learning_rate)\n",
    "print_interval = 20\n",
    "ave_reward = 0\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - tau) + param.data * tau\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of episode :20, avg score : 191.2\n",
      "# of episode :40, avg score : 243.2\n",
      "# of episode :60, avg score : 169.1\n",
      "# of episode :80, avg score : 207.2\n",
      "# of episode :100, avg score : 214.7\n",
      "# of episode :120, avg score : 126.0\n",
      "# of episode :140, avg score : 143.0\n",
      "# of episode :160, avg score : 87.7\n",
      "# of episode :180, avg score : 92.0\n",
      "# of episode :200, avg score : 69.7\n",
      "# of episode :220, avg score : 78.7\n",
      "# of episode :240, avg score : 101.2\n",
      "# of episode :260, avg score : 129.4\n",
      "# of episode :280, avg score : 85.0\n",
      "# of episode :300, avg score : 138.5\n",
      "# of episode :320, avg score : 76.9\n",
      "# of episode :340, avg score : 117.7\n",
      "# of episode :360, avg score : 77.0\n",
      "# of episode :380, avg score : 96.2\n",
      "# of episode :400, avg score : 80.2\n",
      "# of episode :420, avg score : 80.2\n",
      "# of episode :440, avg score : 68.9\n",
      "# of episode :460, avg score : 78.3\n",
      "# of episode :480, avg score : 82.2\n",
      "# of episode :500, avg score : 72.5\n",
      "# of episode :520, avg score : 98.2\n",
      "# of episode :540, avg score : 93.8\n",
      "# of episode :560, avg score : 95.3\n",
      "# of episode :580, avg score : 117.2\n",
      "# of episode :600, avg score : 119.5\n",
      "# of episode :620, avg score : 100.3\n",
      "# of episode :640, avg score : 73.2\n",
      "# of episode :660, avg score : 87.4\n",
      "# of episode :680, avg score : 107.1\n",
      "# of episode :700, avg score : 76.2\n",
      "# of episode :720, avg score : 105.7\n",
      "# of episode :740, avg score : 82.0\n",
      "# of episode :760, avg score : 81.5\n",
      "# of episode :780, avg score : 73.9\n",
      "# of episode :800, avg score : 83.8\n",
      "# of episode :820, avg score : 75.0\n",
      "# of episode :840, avg score : 62.9\n",
      "# of episode :860, avg score : 73.5\n",
      "# of episode :880, avg score : 72.8\n",
      "# of episode :900, avg score : 110.2\n",
      "# of episode :920, avg score : 93.8\n",
      "# of episode :940, avg score : 86.3\n",
      "# of episode :960, avg score : 48.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-74a775cf7a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0msoft_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0msoft_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-132-839655373f4d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\unity\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\unity\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    building.empty_building()\n",
    "    while building.target == 0 :\n",
    "        building.generate_people(add_people_prob)\n",
    "    first_state = building.target\n",
    "    state = building.get_state()\n",
    "    done = False\n",
    "    global_step = 0\n",
    "    while not done:\n",
    "        for t in range(T_horizon):\n",
    "            global_step += 1\n",
    "            if (global_step % 25 == 0) & global_step > 0 :\n",
    "                #building.generate_people(add_people_prob/2)\n",
    "                pass\n",
    "            action_prob = model.get_action(torch.from_numpy(np.array(state)).float())\n",
    "            m = Categorical(action_prob)\n",
    "            action = m.sample().item()\n",
    "            building.perform_action([action])\n",
    "            reward = building.get_reward() \n",
    "            \n",
    "            next_state = building.get_state()\n",
    "            finished = next_state.copy()\n",
    "            del finished[-2:]\n",
    "            if (sum(finished) == 0.0) :\n",
    "                reward = 100. #* building.target\n",
    "                done = True\n",
    "            #print(sum(finished))\n",
    "            #print('global_step : ',global_step,'state : ',state, 'action : ', action, 'reward : ',reward/float(first_state), 'done : ',done)\n",
    "            #print('global_step : ',global_step,'state : ',state, 'action : ', action, 'reward : ',reward/10., 'done : ',done)\n",
    "            #model.put_data((state, action, reward/float(first_state), next_state, action_prob[action].item(), done))\n",
    "            model.put_data((state, action, reward/100.0, next_state, action_prob[action].item(), done))\n",
    "            state = next_state\n",
    "            \n",
    "            if done or (global_step > 300):\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        model.train()\n",
    "        soft_update(model.fc2,model.fc2_target,0.001)\n",
    "        soft_update(model.value,model.value_target,0.001)\n",
    "    ave_reward += global_step \n",
    "    #print(\"Epoch: %d Step: %d Average Reward: %.4f\"%(epoch, global_step, ave_reward/global_step))\n",
    "    if epoch%print_interval==0 and epoch!=0:\n",
    "        print(\"# of episode :{}, avg score : {:.1f}\".format(epoch, ave_reward/print_interval))\n",
    "        ave_reward = 0\n",
    "    if (epoch % 100 == 0 )& (epoch != 0):\n",
    "        torch.save(model.state_dict(), './model_weights/model_'+str(epoch))\n",
    "    reward_list.append(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agent(\n",
       "  (fc1): Linear(in_features=17, out_features=256, bias=True)\n",
       "  (policy): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (fc2): Linear(in_features=17, out_features=256, bias=True)\n",
       "  (value): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (fc2_target): Linear(in_features=17, out_features=256, bias=True)\n",
       "  (value_target): Linear(in_features=256, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).repeat(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0026, -0.0026, -0.0026, -0.0026, -0.0026],\n",
       "        [ 0.0585,  0.0585,  0.0585,  0.0585,  0.0585],\n",
       "        [ 0.0302,  0.0302,  0.0302,  0.0302,  0.0302],\n",
       "        [-0.0322, -0.0322, -0.0322, -0.0322, -0.0322],\n",
       "        [ 0.0053,  0.0053,  0.0053,  0.0053,  0.0053]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(-1,5,1).repeat(1,1,5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0132,  0.2926,  0.1511, -0.1609,  0.0267], grad_fn=<SumBackward2>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(b.reshape(-1,5,1).repeat(1,1,5)[0],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0592, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.sum(b.reshape(-1,5,1).repeat(1,1,5)[0],dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = b.reshape(-1,5,1).repeat(1,1,5)[0] + a.reshape(-1,1,5).repeat(1,5,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = torch.where(test>=0,torch.tensor([0]),torch.tensor([1])).float() * torch.tensor([0.1-1,0.3-1,0.5-1,0.7-1,0.9-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9000,  0.3000,  0.5000, -0.3000,  0.9000],\n",
       "        [ 0.1000,  0.3000,  0.5000,  0.7000,  0.9000],\n",
       "        [ 0.1000,  0.3000,  0.5000, -0.3000,  0.9000],\n",
       "        [-0.9000,  0.3000, -0.5000, -0.3000, -0.1000],\n",
       "        [ 0.1000,  0.3000,  0.5000, -0.3000,  0.9000]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 + test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_2 = torch.where(test<0,torch.tensor([0]),torch.tensor([1])).float() * torch.tensor([0.1,0.3,0.5,0.7,0.9]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9000,  0.3000,  0.5000, -0.3000,  0.9000],\n",
       "        [ 0.1000,  0.3000,  0.5000,  0.7000,  0.9000],\n",
       "        [ 0.1000,  0.3000,  0.5000, -0.3000,  0.9000],\n",
       "        [-0.9000,  0.3000, -0.5000, -0.3000, -0.1000],\n",
       "        [ 0.1000,  0.3000,  0.5000, -0.3000,  0.9000]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1+test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9000, -0.0000, -0.0000, -0.3000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.3000, -0.0000],\n",
       "        [-0.9000, -0.0000, -0.5000, -0.3000, -0.1000],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.3000, -0.0000]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3000, 0.5000, 0.0000, 0.9000],\n",
       "        [0.1000, 0.3000, 0.5000, 0.7000, 0.9000],\n",
       "        [0.1000, 0.3000, 0.5000, 0.0000, 0.9000],\n",
       "        [0.0000, 0.3000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1000, 0.3000, 0.5000, 0.0000, 0.9000]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0026, -0.0053, -0.0079, -0.0106, -0.0132],\n",
       "        [ 0.0585,  0.1170,  0.1755,  0.2341,  0.2926],\n",
       "        [ 0.0302,  0.0605,  0.0907,  0.1209,  0.1511],\n",
       "        [-0.0322, -0.0644, -0.0965, -0.1287, -0.1609],\n",
       "        [ 0.0053,  0.0107,  0.0160,  0.0213,  0.0267]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(-1,5,1).repeat(1,1,5)[0] * torch.tensor([1,2,3,4,5]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "        [-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "        [-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "        [-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "        [-0.0026,  0.0585,  0.0302, -0.0322,  0.0053]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,1,5).repeat(1,5,1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0445, -0.0872, -0.0112, -0.0145,  0.0065],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0445, -0.0872, -0.0112, -0.0145,  0.0065],\n",
       "         [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270],\n",
       "         [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270],\n",
       "         [ 0.0473,  0.0051,  0.0144, -0.0305, -0.0393],\n",
       "         [ 0.0473,  0.0051,  0.0144, -0.0305, -0.0393],\n",
       "         [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270],\n",
       "         [-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0445, -0.0872, -0.0112, -0.0145,  0.0065],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "         [ 0.0445, -0.0872, -0.0112, -0.0145,  0.0065],\n",
       "         [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270],\n",
       "         [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270],\n",
       "         [ 0.0473,  0.0051,  0.0144, -0.0305, -0.0393],\n",
       "         [ 0.0473,  0.0051,  0.0144, -0.0305, -0.0393],\n",
       "         [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270]]],\n",
       "       grad_fn=<RepeatBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0445, -0.0872, -0.0112, -0.0145,  0.0065],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010]],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "        [-0.0026,  0.0585,  0.0302, -0.0322,  0.0053],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0445, -0.0872, -0.0112, -0.0145,  0.0065],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0435, -0.0604, -0.0112, -0.0123, -0.0010],\n",
       "        [ 0.0445, -0.0872, -0.0112, -0.0145,  0.0065],\n",
       "        [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270],\n",
       "        [ 0.0584, -0.0220,  0.0260, -0.0273, -0.0270],\n",
       "        [ 0.0473,  0.0051,  0.0144, -0.0305, -0.0393],\n",
       "        [ 0.0473,  0.0051,  0.0144, -0.0305, -0.0393]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unity",
   "language": "python",
   "name": "unity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
